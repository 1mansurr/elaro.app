name: Daily Database Backup

on:
  schedule:
    # Run daily at 2 AM UTC (adjust timezone as needed)
    - cron: '0 2 * * *'
  workflow_dispatch: # Allow manual trigger

jobs:
  backup:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Verify required secrets
        run: |
          if [ -z "${{ secrets.SUPABASE_URL }}" ]; then
            echo "‚ùå SUPABASE_URL secret is not set"
            exit 1
          fi
          if [ -z "${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}" ]; then
            echo "‚ùå SUPABASE_SERVICE_ROLE_KEY secret is not set"
            exit 1
          fi
          if [ -z "${{ secrets.SUPABASE_DB_PASSWORD }}" ]; then
            echo "‚ùå SUPABASE_DB_PASSWORD secret is not set"
            exit 1
          fi
          echo "‚úÖ Required secrets are configured"

      - name: Install PostgreSQL client
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client

      - name: Create backup
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          DB_PASSWORD: ${{ secrets.SUPABASE_DB_PASSWORD }}
        run: |
          mkdir -p backups/daily
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          BACKUP_FILE="backups/daily/daily_backup_${TIMESTAMP}.sql.gz"
          
          # Extract database host from SUPABASE_URL
          # Format: https://xxxxx.supabase.co
          DB_HOST=$(echo "$SUPABASE_URL" | sed 's|https://||' | sed 's|\.supabase\.co.*||')
          
          echo "üîó Connecting to database host: ${DB_HOST}.supabase.co"
          
          # Use pg_dump with database password
          # Note: Supabase uses 'postgres' as the database name
          export PGPASSWORD="$DB_PASSWORD"
          
          if ! pg_dump \
            -h ${DB_HOST}.supabase.co \
            -p 5432 \
            -U postgres \
            -d postgres \
            --no-owner \
            --no-acl \
            | gzip > "$BACKUP_FILE"; then
            echo "‚ùå Failed to create database backup"
            unset PGPASSWORD
            exit 1
          fi
          
          unset PGPASSWORD
          
          if [ ! -f "$BACKUP_FILE" ] || [ ! -s "$BACKUP_FILE" ]; then
            echo "‚ùå Backup file was not created or is empty"
            exit 1
          fi
          
          echo "‚úÖ Backup created: $BACKUP_FILE"
          ls -lh "$BACKUP_FILE"

      - name: Upload backup to artifacts
        uses: actions/upload-artifact@v4
        with:
          name: database-backup-${{ github.run_number }}
          path: backups/daily/daily_backup_*.sql.gz
          retention-days: 7
          if-no-files-found: error

      - name: Clean up old backups (local)
        run: |
          find backups/daily -name "daily_backup_*.sql.gz" -type f -mtime +7 -delete || true

      # Optional: Upload to cloud storage (S3, Google Cloud, etc.)
      # Uncomment and configure as needed:
      #
      # - name: Upload to S3
      #   uses: aws-actions/configure-aws-credentials@v4
      #   with:
      #     aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
      #     aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      #     aws-region: us-east-1
      #   run: |
      #     aws s3 cp backups/daily/daily_backup_*.sql.gz s3://your-backup-bucket/daily/
      #
      # - name: Upload to Google Cloud Storage
      #   uses: google-github-actions/upload-cloud-storage@v1
      #   with:
      #     path: backups/daily/daily_backup_*.sql.gz
      #     destination: gs://your-backup-bucket/daily/
      #     credentials: ${{ secrets.GCP_SA_KEY }}

